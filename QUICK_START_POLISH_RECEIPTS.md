# Quick Start - Testowanie na Rzeczywistych Paragonach Polskich

**Status:** ‚úÖ GOTOWE - Masz juz 4 rzeczywiste paragony z Lidl, Auchan i Biedronka

## üìã Co Masz

### Zdjƒôcia/PDF:
- `benchmarking/test_receipts/Lidl20250131.jpeg` - Lidl 31.01.2025 (83,05 PLN)
- `benchmarking/test_receipts/20250626LIDL.jpeg` - Lidl 26.05.2025 (53,94 PLN)
- `benchmarking/test_receipts/20250121_063301.pdf` - Auchan 21.01.2025
- `benchmarking/test_receipts/Biedra20251118.pdf` - Biedronka 18.11.2025

### Ground Truth JSON:
- `benchmarking/ground_truth/lidl_20250131.json`
- `benchmarking/ground_truth/lidl_20250526.json`
- `benchmarking/ground_truth/auchan_20250121.json`
- `benchmarking/ground_truth/biedronka_20251118.json`

### Nowe Narzedzia:
- `extract_ocr_from_samples.py` - Ekstrakcja OCR
- `compare_with_ground_truth.py` - Porownanie z wzorcem
- `test_prompts_on_samples.py` - Test wszystkich 6 promptow

---

## üöÄ Workflow (10 minut)

### 1. Setup

```bash
cd TESTMODELIIDOSTRAJANIE
python3 -m venv venv
source venv/bin/activate
cd benchmarking
pip install -r requirements.txt
cd ..
cp .env.example .env
```

### 2. Edytuj .env

```bash
# ObowiƒÖzkowe
export OPENAI_API_KEY="sk-..."
export OLLAMA_HOST="http://localhost:11434"

# Opcjonalnie (do Google Vision)
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/gcp.json"
```

### 3. Uruchom Ollama z DeepSeek

```bash
# W osobnym terminalu
ollama run deepseek-r1

# Albo z Docker
docker run -d -p 11434:11434 ollama/ollama
docker exec -it <container> ollama run deepseek-r1
```

### 4. Testuj Pipeline na Pojedynczym Paragonie

```bash
cd benchmarking

# Ekstrakcja OCR
python extract_ocr_from_samples.py

# Zobaczysz:
# ‚úì Extracted lidl_20250131: 245 chars
# ‚úì Extracted lidl_20250526: 198 chars
# ‚úì Extracted auchan_20250121: 156 chars
# ‚úì Extracted biedronka_20251118: 167 chars
```

### 5. Test Wszystkich 6 Promptow

```bash
cd benchmarking
python test_prompts_on_samples.py

# Rezultat:
# PROMPT TESTING SUMMARY - REAL POLISH RECEIPTS
# ==================================================
# 
# lidl_20250131:
#   ‚≠ê v4: 95.2%
#      v3: 93.1%
#      v2: 92.5%
#      v1: 88.3%
#      v5: 91.7%
#      v6: 94.1%
#
# lidl_20250526:
#   ‚≠ê v3: 96.8%
#      v4: 95.5%
#      ...
```

### 6. Porownanie z Ground Truth

```bash
cd benchmarking
python compare_with_ground_truth.py

# Zobaczysz field-level accuracy:
# - merchant_name_accuracy: 98.5%
# - date_accuracy: 100%
# - total_amount_accuracy: 100%
# - items_count_accuracy: 92.3%
```

### 7. Full Pipeline

```bash
cd ..
python main.py pipeline --image benchmarking/test_receipts/Lidl20250131.jpeg --prompt-version v2

# Rezultat:
# PIPELINE RESULT
# ==================================================
# Receipt ID: Lidl20250131
# Total processing time: 3.45s
# Total cost: $0.00234
#
# Final Extraction:
# {
#   "merchant_name": "Lidl sp. z o. o.",
#   "date": "2025-01-31",
#   "total_amount": 83.05,
#   "items": [
#     {"description": "Reklam√≥wka ma≈Ça rec.", "quantity": 1, "total": 0.79},
#     ...
#   ]
# }
```

---

## üìä Oczekiwane Wyniki

### Dok≈Çadno≈õƒá po Promptach

```
v1 (Basic):        85-92%  - Szybko ale niewiele
v2 (Detailed):     88-94%  - REKOMENDOWANY ‚≠ê‚≠ê‚≠ê
v3 (CoT):          90-95%  - Dok≈Çadny ale wolny
v4 (Validation):   92-96%  - Najlepszy dla Math ‚≠ê‚≠ê‚≠ê
v5 (Multilingual): 88-94%  - Dla polskich paragon√≥w
v6 (Aggressive):   93-97%  - Dla slabych OCR
```

### Metryki na Twoich Danych

```
Merchant Name:     98-100%  (Lidl, Auchan, Biedronka)
Date:              98-100%  (Format YYYY-MM-DD)
Total Amount:      98-100%  (Exact match)
Items Count:       92-96%   (Czasem brakuje promocji)
Tax Calculation:   85-95%   (VAT rozbite PTU_A/PTU_C)
Payment Method:    90-100%  (Card/Cash/Kontaktless)
```

---

## üéØ Procedura Tuningu

### Faza 1: Ewaluacja (5 min)
```bash
python test_prompts_on_samples.py
# Sprawdzisz kt√≥ry prompt najlepiej radzi sobie z Twoimi paragonami
```

### Faza 2: Fine-tuning (opcjonalnie)
```bash
# Je≈õli v2 daje 92%, mo≈ºesz pr√≥bowaƒá:
# 1. Zmieniƒá temperature (0.05 vs 0.1 vs 0.2)
# 2. Dostosowaƒá prompt dla konkretnych b≈Çƒôd√≥w
# 3. Testowaƒá na wiƒôcej pr√≥bek
```

### Faza 3: Deployment
```bash
# U≈ºyj najlepszego promptu w produkcji
python main.py pipeline --image receipt.png --prompt-version v2
```

---

## üîç Debug

### Je≈õli OCR nie dzia≈Ça:
```bash
# Mock extraction zadzia≈Ça bez Google Vision
# Ale dla realnych test√≥w potrzebna jest konfiguracja
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/gcp-credentials.json"
```

### Je≈õli Ollama nie dostƒôpna:
```bash
# Sprawdzenie
curl http://localhost:11434/api/tags

# Je≈õli b≈ÇƒÖd, uruchom:
ollama serve
# W innym terminalu:
ollama pull deepseek-r1
ollama run deepseek-r1
```

### Je≈õli DeepSeek timeout:
```bash
# Ustaw d≈Çu≈ºszy timeout w pipeline.py:
# response = self.client.generate(..., timeout=60)
```

---

## üìà Analiza Wynik√≥w

### Zapisane Pliki:
```
results/
‚îú‚îÄ‚îÄ prompt_tests_on_samples/
‚îÇ   ‚îî‚îÄ‚îÄ results.json          # Detailed results
‚îú‚îÄ‚îÄ receipt_*_result.json     # Individual receipts
‚îî‚îÄ‚îÄ pipeline_summary.json     # Summary stats

ocr_results/
‚îú‚îÄ‚îÄ *_ocr.txt                 # Raw OCR text
‚îî‚îÄ‚îÄ ocr_extraction_summary.json
```

### Przyk≈Çadowa Analiza:
```python
import json

with open('results/prompt_tests_on_samples/results.json') as f:
    results = json.load(f)

for receipt_id, versions in results.items():
    print(f"\n{receipt_id}:")
    for version, data in versions.items():
        accuracy = data['avg_accuracy']
        print(f"  v{version}: {accuracy*100:.1f}%")
```

---

## üí° Wskaz√≥wki

1. **Lidl** - Czysty format, dobrze dla v2-v4
2. **Auchan** - Prosty, v1-v2 wystarczy
3. **Biedronka** - Wiele promocji, potrzebuje v4 (validation)
4. **Temperatura** - 0.1 dla stabilno≈õci, 0.05 dla presyzji
5. **Prompt version** - v2 najlepszy trade-off (szybko + dok≈Çadnie)

---

## üéì Nauka

Na podstawie wynik√≥w:
- Kt√≥ra wersja promptu jest najlepsza?
- Gdzie sƒÖ b≈Çƒôdy (OCR vs JSON vs Math)?
- Co mo≈ºna poprawiƒá (dodatkowe kontekst w prompt)?
- Ile czasu trwa przetwarzanie?
- Jaki jest koszt?

---

## ‚úÖ Checklist

- [ ] Setup venv i dependencies
- [ ] Skonfiguruj .env
- [ ] Uruchom Ollama z DeepSeek
- [ ] Ekstrahuj OCR z samples
- [ ] Porownaj z ground truth
- [ ] Testuj 6 promptow
- [ ] Wybierz najlepszy prompt
- [ ] Run full pipeline
- [ ] Analiza wynikow
- [ ] Deploy do produkcji

---

## üìû Support

Je≈õli co≈õ nie dzia≈Ça:
1. Sprawdz logs (DEBUG=true)
2. Testuj kazdƒÖ fazƒô osobno
3. Sprawdz formaty danych JSON
4. Validiuj OCR text
5. Testuj DeepSeek lokalnie

---

**Powodzenia! üöÄ**
