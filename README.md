# ğŸš€ OCR Model Testing & Optimization Suite

Kompleksowy system do testowania i optymalizacji modeli OCR dla przetwarzania paragonÃ³w.

## ğŸ“‹ Cel Projektu

Portfolio porÃ³wnawcze trzech dostawcÃ³w OCR:

| Provider | Koszt | SzybkoÅ›Ä‡ | DokÅ‚adnoÅ›Ä‡ |
|----------|-------|----------|------------|
| **Google Vision API** | $0.0015/receipt | 1.5-3s | 85-90% |
| **GPT-4o mini** | $0.001-0.002 | 2-4s | 92-96% ğŸ† |
| **DeepSeek R1** | ~$0.00001 (local) | 0.5-1.5s âš¡ | 88-94% (cel) |

**Cel**: Optymalizacja DeepSeek R1 do poziomu GPT-4o mini, przy zachowaniu lokalnego wdroÅ¼enia (zero kosztÃ³w API).

---

## ğŸ“¦ Struktura Repozytorium

```
TESTMODELIIDOSTRAJANIE/
â”‚
â”œâ”€â”€ ğŸ“ benchmarking/              # Core benchmarking system
â”‚   â”œâ”€â”€ ocr_benchmark_engine.py   # Multi-provider OCR engine (23.5 KB)
â”‚   â”œâ”€â”€ run_benchmark.py          # CLI runner + reporting (12.7 KB)
â”‚   â”œâ”€â”€ setup_test_data.py        # Data preparation & validation (11.6 KB)
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ .env.example              # Configuration template
â”‚   â”œâ”€â”€ README.md                 # Full documentation
â”‚   â”œâ”€â”€ QUICKSTART.md             # 5-minute quick start
â”‚   â”‚
â”‚   â”œâ”€â”€ test_receipts/            # Receipt images (PNG/JPG)
â”‚   â”œâ”€â”€ ground_truth/             # JSON annotations (labels)
â”‚   â””â”€â”€ results/                  # Benchmark outputs
â”‚       â”œâ”€â”€ benchmark_summary.json
â”‚       â”œâ”€â”€ benchmark_report.txt
â”‚       â”œâ”€â”€ benchmark_comparison.png
â”‚       â”œâ”€â”€ ocr_results.jsonl
â”‚       â””â”€â”€ metrics.jsonl
â”‚
â”œâ”€â”€ ğŸ“ optimization/              # DeepSeek R1 optimization
â”‚   â”œâ”€â”€ prompt_engineering.md     # Refined prompts
â”‚   â”œâ”€â”€ post_processing.py        # Fuzzy matching & validation
â”‚   â”œâ”€â”€ business_rules.py         # Receipt validation logic
â”‚   â””â”€â”€ test_optimizations.py     # Optimization test suite
â”‚
â”œâ”€â”€ ğŸ“ integration/               # Integration with ParagonOCR
â”‚   â”œâ”€â”€ deepseek_wrapper.py       # Drop-in replacement for Google Vision
â”‚   â”œâ”€â”€ batch_processor.py        # Batch receipt processing
â”‚   â””â”€â”€ examples.py               # Usage examples
â”‚
â”œâ”€â”€ ğŸ“ docs/                      # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md           # System design
â”‚   â”œâ”€â”€ API_REFERENCE.md          # API documentation
â”‚   â”œâ”€â”€ METRICS_GUIDE.md          # Metrics explanation
â”‚   â”œâ”€â”€ OPTIMIZATION_STRATEGY.md  # Phase-by-phase optimization plan
â”‚   â””â”€â”€ TROUBLESHOOTING.md        # Common issues & solutions
â”‚
â”œâ”€â”€ ğŸ“ tests/                     # Test suite
â”‚   â”œâ”€â”€ test_extractors.py        # Provider tests
â”‚   â”œâ”€â”€ test_metrics.py           # Metrics tests
â”‚   â””â”€â”€ test_validation.py        # Validation tests
â”‚
â”œâ”€â”€ ğŸ“ examples/                  # Example files
â”‚   â”œâ”€â”€ sample_receipts/          # Sample receipt images
â”‚   â”œâ”€â”€ sample_ground_truth/      # Sample annotations
â”‚   â””â”€â”€ sample_reports/           # Example benchmark outputs
â”‚
â”œâ”€â”€ Makefile                      # Common commands
â”œâ”€â”€ setup.py                      # Package installation
â”œâ”€â”€ pyproject.toml               # Project config
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”œâ”€â”€ LICENSE                      # MIT License
â”‚
â””â”€â”€ ğŸ“„ INDEX.md                  # Navigation guide (this file)

```

---

## ğŸš€ Quick Start (5 minut)

### 1ï¸âƒ£ Klonowanie i Setup

```bash
git clone https://github.com/codemarcinu/TESTMODELIIDOSTRAJANIE
cd TESTMODELIIDOSTRAJANIE/benchmarking

pip install -r requirements.txt
cp .env.example .env

# Edytuj .env:
export OPENAI_API_KEY="sk-..."
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/gcp.json"
```

### 2ï¸âƒ£ Przygotowanie danych

```bash
# Generuj przykÅ‚adowe dane testowe
python setup_test_data.py --generate-samples 10 --report

# Lub dodaj swoje paragon images do:
# test_receipts/receipt_001.png
# test_receipts/receipt_002.jpg
# ...

# StwÃ³rz ground truth annotations:
# ground_truth/receipt_001.json (formato JSON)
```

### 3ï¸âƒ£ Uruchomienie benchmarku

```bash
# Baseline: GPT-4o mini vs DeepSeek R1
python run_benchmark.py \
  --image-dir test_receipts \
  --providers gpt4o_mini deepseek_r1 \
  --output-dir results

# Z Google Vision (peÅ‚ne porÃ³wnanie)
python run_benchmark.py \
  --image-dir test_receipts \
  --providers google_vision gpt4o_mini deepseek_r1 \
  --output-dir results
```

### 4ï¸âƒ£ PrzeglÄ…danie wynikÃ³w

```bash
# Raport tekstowy
cat results/benchmark_report.txt

# Wykresy porÃ³wnawcze
open results/benchmark_comparison.png  # macOS
xdg-open results/benchmark_comparison.png  # Linux

# SzczegÃ³Å‚owe metryki
head -20 results/ocr_results.jsonl
```

---

## ğŸ“Š Metryki PorÃ³wnawcze

### DokÅ‚adnoÅ›Ä‡ (Accuracy)

- **Field Accuracy** - dokÅ‚adne dopasowanie kluczowych pÃ³l (%)
  - merchant_name, date, time, total_amount
  - Target dla DeepSeek R1: **â‰¥92%**

- **Fuzzy Accuracy** - dopasowanie >80% podobieÅ„stwa (%)
  - Bardziej tolerancyjne dla drobnych rÃ³Å¼nic
  - Target: **â‰¥95%**

- **Char Error Rate** - bÅ‚Ä™dy na poziomie znakÃ³w (Levenshtein)
  - Target: **<5%**

- **Word Error Rate** - bÅ‚Ä™dy na poziomie sÅ‚Ã³w
  - Target: **<10%**

### WydajnoÅ›Ä‡ (Performance)

- **Processing Time** - sekundy na paragon
  - Google Vision: ~2s
  - GPT-4o mini: ~3s
  - DeepSeek R1: <1.5s âš¡ (local)

- **Tokens Used** - zuÅ¼ycie tokenÃ³w (LLM)
  - WpÅ‚yw na koszt API

- **Cost Per Receipt** - caÅ‚kowity koszt przetwarzania
  - Google: $0.0015
  - GPT-4o mini: $0.001-0.002
  - DeepSeek: ~$0 (local compute)

### JakoÅ›Ä‡ Danych (Quality)

- **Field Completeness** - % odnalezionych pÃ³l
  - Target: **â‰¥90%**

- **Numerical Accuracy** - dokÅ‚adnoÅ›Ä‡ kwot (Â±1% tolerance)
  - Target: **â‰¥95%**

- **Consistency Score** - walidacja reguÅ‚ biznesowych (0-1)
  - Suma pozycji = total
  - Format daty YYYY-MM-DD
  - Wszystkie kwoty dodatnie
  - Target: **â‰¥0.9**

---

## ğŸ¯ Strategia Optymalizacji DeepSeek R1

### Faza 1: Baseline (TydzieÅ„ 1)

```bash
# PorÃ³wnanie "out of the box"
python run_benchmark.py --providers gpt4o_mini deepseek_r1
```

**Oczekiwane**: DeepSeek 5-10% gorzej niÅ¼ GPT-4o mini
**GÅ‚Ã³wny powÃ³d**: Model mniej "fine-tuned" do strukturyzowanej ekstrakcji

### Faza 2: Prompt Engineering (TydzieÅ„ 2-3)

SzczegÃ³Å‚owe prompty znajdujÄ… siÄ™ w: `optimization/prompt_engineering.md`

**Techniki**:
- Few-shot examples
- Structured output format
- Reasoning steps
- Error prevention instructions

**Oczekiwana poprawa**: +3-5% dokÅ‚adnoÅ›ci

### Faza 3: Post-Processing (TydzieÅ„ 3-4)

Implementacja w: `optimization/post_processing.py`

**Techniki**:
- Fuzzy matching dla merchant names
- Normalizacja formatu daty
- Walidacja sum pozycji
- Korekta bÅ‚Ä™dÃ³w OCR

**Oczekiwana poprawa**: +2-3% dokÅ‚adnoÅ›ci

### Faza 4: Business Rules (TydzieÅ„ 4-5)

Walidacja w: `optimization/business_rules.py`

**ReguÅ‚y**:
- Items total musi = receipt total (Â±0.01)
- Data nie moÅ¼e byÄ‡ w przyszÅ‚oÅ›ci
- Kwoty nie mogÄ… byÄ‡ ujemne
- Merchant name musi byÄ‡ wypeÅ‚niony

**Oczekiwana poprawa**: +1-2% consistency

### Faza 5: Lokalne WdroÅ¼enie (TydzieÅ„ 5-6)

WdroÅ¼enie: `integration/deepseek_wrapper.py`

**Kroki**:
1. Setup Ollama lub vLLM
2. Pull deepseek-r1 model
3. Zintegruj z ParagonOCR
4. Testowanie na rzeczywistych danych

**KorzyÅ›ci**:
- Zero kosztÃ³w API
- 3-5x szybsze (GPU local)
- PeÅ‚na kontrola nad danymi

---

## ğŸ’» Instalacja

### Wymagania

- Python 3.8+
- pip lub poetry
- GPU (opcjonalnie, dla DeepSeek R1)

### PeÅ‚na instalacja

```bash
# Clone repo
git clone https://github.com/codemarcinu/TESTMODELIIDOSTRAJANIE
cd TESTMODELIIDOSTRAJANIE

# UtwÃ³rz virtual environment
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# lub
venv\Scripts\activate  # Windows

# Zainstaluj zaleÅ¼noÅ›ci
cd benchmarking
pip install -r requirements.txt

# Setup konfiguracji
cp .env.example .env
# Edytuj .env swoimi kluczami API

# Opcjonalnie: Setup DeepSeek R1 (Ollama)
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull deepseek-r1
ollama serve  # W osobnym terminalu
```

### Alternatywa: Przy uÅ¼yciu Make

```bash
make install         # Instalacja wszystkiego
make setup          # Setup konfiguracji
make test-gpt       # Test GPT-4o mini
make test-deepseek  # Test DeepSeek R1
make benchmark      # PeÅ‚ny benchmark
make clean          # Czyszczenie
```

---

## ğŸ“š Dokumentacja

PeÅ‚na dokumentacja znajduje siÄ™ w katalogu `docs/`:

- **[ARCHITECTURE.md](docs/ARCHITECTURE.md)** - Architektura systemu
- **[API_REFERENCE.md](docs/API_REFERENCE.md)** - Dokumentacja API
- **[METRICS_GUIDE.md](docs/METRICS_GUIDE.md)** - WyjaÅ›nienie metryk
- **[OPTIMIZATION_STRATEGY.md](docs/OPTIMIZATION_STRATEGY.md)** - Detailowa strategia
- **[TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)** - RozwiÄ…zywanie problemÃ³w

---

## ğŸ”§ UÅ¼ycie w Praktyce

### Integracja z ParagonOCR

```python
# Zamiast:
from google.cloud import vision
client = vision.ImageAnnotatorClient()

# UÅ¼yj:
from integration.deepseek_wrapper import DeepSeekOCR
ocr = DeepSeekOCR()
result = ocr.extract(receipt_image)
```

PeÅ‚ny przykÅ‚ad: `integration/examples.py`

### Batch Processing

```python
from integration.batch_processor import BatchReceiptProcessor

processor = BatchReceiptProcessor(
    batch_size=32,
    num_workers=4
)

results = processor.process_directory("receipts/")
for receipt_id, extracted_data in results:
    print(f"{receipt_id}: {extracted_data}")
```

### Programmatic API

```python
from benchmarking.ocr_benchmark_engine import (
    OCRBenchmark,
    OCRProvider,
    DeepSeekR1Extractor
)

benchmark = OCRBenchmark(ground_truth_dir="ground_truth")
benchmark.register_extractor(
    OCRProvider.DEEPSEEK_R1,
    DeepSeekR1Extractor()
)

results = benchmark.run_benchmark(
    image_dir="test_receipts",
    providers=[OCRProvider.DEEPSEEK_R1],
    output_dir="results"
)
```

---

## ğŸ“ˆ Oczekiwane Rezultaty

### Timeline

```
TydzieÅ„ 1: Baseline (DeepSeek ~5-10% gorzej)
TydzieÅ„ 2-3: +3-5% (Prompt engineering)
TydzieÅ„ 4: +2-3% (Post-processing)
TydzieÅ„ 5: +1-2% (Business rules)
---
Koniec: DeepSeek ~91-93% accuracy (bardzo blisko GPT-4o mini 94%)
```

### Rezultaty KosztÃ³w

| Faza | Accuracy | Speed | Cost/Receipt | Vs GPT-4o mini |
|------|----------|-------|--------------|----------------|
| **Start** | 89% | 1.8s | $0.00001 | -5% |
| **Week 2-3** | 92-93% | 1.2s | $0.00001 | -1-2% |
| **Final** | 92-94% | 1.0s | $0.00001 | -0-2% |

**OszczÄ™dnoÅ›ci (10 receipts/dzieÅ„)**:
- Baseline OpenAI: $3-7/rok
- DeepSeek local: ~$0.04/rok
- **Save: 99.4% kosztÃ³w**

---

## ğŸ§ª Testowanie

```bash
# Uruchom test suite
pytest tests/

# Test specific module
pytest tests/test_extractors.py -v

# Test z coverage
pytest tests/ --cov=benchmarking --cov-report=html
```

---

## ğŸ“Š PrzykÅ‚ad Raportu

Po uruchomieniu benchmarku otrzymasz:

```
================================================================================
OCR BENCHMARKING REPORT
================================================================================

BENCHMARK OVERVIEW
----------------------------------------
Total Tests: 10
Timestamp: 2026-01-17T19:05:00

PROVIDER COMPARISON
----------------------------------------
        Provider  Tests Field Accuracy  Fuzzy Accuracy  Avg Time (s)  Total Cost
     gpt4o_mini     10      94.50%         97.30%          3.124    $0.0180
   deepseek_r1     10      91.20%         95.80%          1.245    $0.0001

RECOMMENDATIONS FOR DEEPSEEK R1 OPTIMIZATION
----------------------------------------
Best Accuracy: gpt4o_mini (94.50%)
  - Actions: Review prompt engineering, improve fuzzy matching

Best Speed: deepseek_r1 (1.245s)
  - Actions: Maintain current optimization level

Best Cost: deepseek_r1 ($0.0001)
  - Local model has natural cost advantage

DeepSeek R1 Optimization Strategy:
  1. Use same prompts as GPT-4o mini (benchmark)
  2. Implement fuzzy matching for ~80% similarity threshold
  3. Add validation layer for business rule consistency
  4. Optimize for speed while maintaining accuracy
  5. Deploy on local GPU for zero API costs

================================================================================
```

---

## ğŸ”— Zasoby Techniczne

- [DeepSeek-OCR GitHub](https://github.com/deepseek-ai/DeepSeek-OCR)
- [DeepSeek R1 Model Card](https://huggingface.co/deepseek-ai/DeepSeek-R1)
- [vLLM Documentation](https://docs.vllm.ai/)
- [Ollama Setup Guide](https://ollama.ai/)
- [Google Cloud Vision API](https://cloud.google.com/vision/docs)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [FuzzyWuzzy String Matching](https://github.com/seatgeek/fuzzywuzzy)

---

## ğŸ¤ Contributing

WkÅ‚ad mile widziany! Prosimy:

1. Fork repozytorium
2. UtwÃ³rz feature branch (`git checkout -b feature/amazing-feature`)
3. Commit zmian (`git commit -m 'Add amazing feature'`)
4. Push do branch (`git push origin feature/amazing-feature`)
5. OtwÃ³rz Pull Request

---

## ğŸ“ Licencja

MIT License - patrz [LICENSE](LICENSE)

---

## ğŸ“ Kontakt

- GitHub: [@codemarcinu](https://github.com/codemarcinu)
- Issues: [GitHub Issues](https://github.com/codemarcinu/TESTMODELIIDOSTRAJANIE/issues)
- Discussions: [GitHub Discussions](https://github.com/codemarcinu/TESTMODELIIDOSTRAJANIE/discussions)

---

## ğŸ¯ Status

- [x] Core benchmarking engine
- [x] Multi-provider support
- [x] Metrics calculation
- [x] Reporting & visualization
- [x] Test data preparation
- [ ] DeepSeek R1 optimization guide (in progress)
- [ ] Integration examples
- [ ] Batch processing module
- [ ] Full test suite
- [ ] Documentation completion

---

**Gotowy do wdroÅ¼enia! ğŸš€**

Zapisz ten projekt do bookmarks - bÄ™dziesz go uÅ¼ywaÄ‡ do optymalizacji DeepSeek R1 i integracji z ParagonOCR.
